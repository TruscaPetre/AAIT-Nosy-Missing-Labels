{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TruscaPetre/AAIT-Nosy-Missing-Labels/blob/main/tutorial%20colab%20missing%20labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing Labels task 1"
      ],
      "metadata": {
        "id": "aIMWvJWPgl8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_lQts5FFgIx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import SubsetRandomSampler, Dataset\n",
        "from torchvision import transforms, datasets \n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import itertools"
      ],
      "metadata": {
        "id": "IhZAai2_gjxi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task1_id = \"1dO1vqCoJm2xwrnr171A6_eW7ikd-alrd\""
      ],
      "metadata": {
        "id": "OjQSLPl1gQJm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace here your ide &id=1iNTm3-9GSN2QjjITBi73ta73gDF_oacf\"\n",
        "# replace here your id 'https://docs.google.com/uc?export=download&id=1dO1vqCoJm2xwrnr171A6_eW7ikd-alrd'\n",
        "# replace here your target name -O task1.tar.gz &&\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1dO1vqCoJm2xwrnr171A6_eW7ikd-alrd' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1dO1vqCoJm2xwrnr171A6_eW7ikd-alrd\" -O task1.tar.gz && rm -rf /tmp/cookies.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcKpxyMqgUPw",
        "outputId": "2eca35a4-d667-49f9-e3b0-6fe1cefed374"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-29 10:33:44--  https://docs.google.com/uc?export=download&confirm=t&id=1dO1vqCoJm2xwrnr171A6_eW7ikd-alrd\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.194.138, 172.217.194.100, 172.217.194.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.194.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-8k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d4p7ncfhbpvid67st0rdrvnabq4h22sq/1672309950000/08997952672865575084/*/1dO1vqCoJm2xwrnr171A6_eW7ikd-alrd?e=download&uuid=4b46f450-ad75-4822-812f-97e083135689 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-12-29 10:33:45--  https://doc-0g-8k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d4p7ncfhbpvid67st0rdrvnabq4h22sq/1672309950000/08997952672865575084/*/1dO1vqCoJm2xwrnr171A6_eW7ikd-alrd?e=download&uuid=4b46f450-ad75-4822-812f-97e083135689\n",
            "Resolving doc-0g-8k-docs.googleusercontent.com (doc-0g-8k-docs.googleusercontent.com)... 142.251.10.132, 2404:6800:4003:c0f::84\n",
            "Connecting to doc-0g-8k-docs.googleusercontent.com (doc-0g-8k-docs.googleusercontent.com)|142.251.10.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75378011 (72M) [application/x-gzip]\n",
            "Saving to: ‘task1.tar.gz’\n",
            "\n",
            "task1.tar.gz        100%[===================>]  71.89M  42.4MB/s    in 1.7s    \n",
            "\n",
            "2022-12-29 10:33:47 (42.4 MB/s) - ‘task1.tar.gz’ saved [75378011/75378011]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!mkdir data\n",
        "!mv task1.tar.gz ./data\n",
        "!tar -xzvf \"/content/data/task1.tar.gz\" -C \"/content/data/\"     #[run this cell to extract tar.gz files]\n",
        "# this may take 12 seconds"
      ],
      "metadata": {
        "id": "zeNl_38DgUKU"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r /content/data/task1"
      ],
      "metadata": {
        "id": "b1TIiMGvNsCu"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up logging"
      ],
      "metadata": {
        "id": "pvhmgZwAewOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This experiment will take long, because there are many trianig periods involved and many changes going on in the data. There are some things that could be helpful to track along the way. So we set up a logger that will do this.\n",
        "\n",
        "We are going to track: \n",
        "- all the hyperparameters for training.\n",
        "- all the seeds for RNG\n",
        "- the images that have been labeled at each iteration. \n",
        "- performance metrics ( we should see them increase through each iteration )\n",
        "\n",
        "We are going to use a dictionary that will save all the data from each iteration of the experiment. Than save that dictionary into a json file for each iteration. \n",
        "\n",
        "There is a json file in the github repository with all the parameters for the first experiment.\n",
        "\n",
        "Some comments about setting those parameters:\n",
        "- The number of epochs is only 10 because according to the training only on the dataset with labeled data, this is the point where the validation set is reaching a saturation. In order to achieve the results faster from self-training, we should keep this number as small as possible."
      ],
      "metadata": {
        "id": "COa9lK9UMopU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_info = {\n",
        "    \"iteration\": 1,\n",
        "    \"image_processing\":{\n",
        "        \"resize\":224,\n",
        "        \"mean\":[0.485, 0.456, 0.406],\n",
        "        \"std\":[0.229, 0.224, 0.225],\n",
        "    },\n",
        "    \"hyperparameters_data\": {\n",
        "        \"batch_size\":32,\n",
        "        \"shuffle_dataloader\":True,\n",
        "        \"num_workers\":4\n",
        "    },\n",
        "    \"random_seeds\":{\n",
        "        \"torch_seed\":42,\n",
        "        \"numpy_seed\":42,\n",
        "        \"cuda_seed\":42,\n",
        "\n",
        "    },\n",
        "    \"hyperparameters_training\":{\n",
        "        \"learning_rate\": 0.0001,\n",
        "        \"scheduler_step_size\":7,\n",
        "        \"scheduler_gamma\":0.1,\n",
        "        \"num_epochs\":10, \n",
        "    },\n",
        "    \"total_unlabeled\":26445,\n",
        "}"
      ],
      "metadata": {
        "id": "9SmFrNSuOwdX"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dictionary to a file\n",
        "with open(\"experiment_info.json\", \"w\") as f:\n",
        "    json.dump(experiment_info, f)"
      ],
      "metadata": {
        "id": "LPHtsWEvO5wS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(experiment_info[\"random_seeds\"][\"numpy_seed\"])\n",
        "torch.manual_seed(experiment_info[\"random_seeds\"][\"torch_seed\"])\n",
        "torch.cuda.manual_seed_all(experiment_info[\"random_seeds\"][\"cuda_seed\"])"
      ],
      "metadata": {
        "id": "rvkgC-zJaTqC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the experiment information from the JSON file\n",
        "with open('experiment_info.json', 'r') as f:\n",
        "    loaded_experiment_info = json.load(f)\n",
        "\n",
        "display(loaded_experiment_info)"
      ],
      "metadata": {
        "id": "jzRL9HznbF9V",
        "outputId": "8ecd61cf-541c-4f1c-e0b5-f50fcbfa5ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'iteration': 1,\n",
              " 'image_processing': {'resize': 224,\n",
              "  'mean': [0.485, 0.456, 0.406],\n",
              "  'std': [0.229, 0.224, 0.225]},\n",
              " 'hyperparameters_data': {'batch_size': 32,\n",
              "  'shuffle_dataloader': True,\n",
              "  'num_workers': 4},\n",
              " 'random_seeds': {'torch_seed': 42, 'numpy_seed': 42, 'cuda_seed': 42},\n",
              " 'hyperparameters_training': {'learning_rate': 0.0001,\n",
              "  'scheduler_step_size': 7,\n",
              "  'scheduler_gamma': 0.1,\n",
              "  'num_epochs': 10}}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount drive"
      ],
      "metadata": {
        "id": "mMp1fV2xezNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each iteration of self-training takes about 1 hour on a GPU. So you might want to save and restart the training a few times. In order to restart the model where we where left of, we are connecting google drive and saving the model there."
      ],
      "metadata": {
        "id": "neHJVMiEe0hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "bNowNASxfOSW",
        "outputId": "eb5ef2f1-2383-405e-9f38-6986d1e3d4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/gdrive/MyDrive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/MyDrive/foo.txt'"
      ],
      "metadata": {
        "id": "3vMEAFjFfOSX",
        "outputId": "ac3cd2a6-7238-4461-cadb-3c0ea39466d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Google Drive!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/gdrive/MyDrive/foo.txt'"
      ],
      "metadata": {
        "id": "oApaDsjmhHlz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pc4qypVPpcu"
      },
      "source": [
        "## Theory about missing labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZCBR60FPpcu"
      },
      "source": [
        "\n",
        "- The classification problem can be tackled using semi-supervised learning methods. There are 3 propular approaches to address semi-supervised learning problems:\n",
        "  - self training\n",
        "  - co-training\n",
        "  - graph-based models\n",
        "- self training \n",
        "  - What is the process?\n",
        "    - First train on labeled data\n",
        "    - Make predictions on the untrained data\n",
        "    - From those predictions, only extract those with high confidence and move them to the training data\n",
        "    - Repeat the process until convergence or no high-confidence exmples left in the unlabeled set.\n",
        "  - Disadvantage is that you can still generate incorrect predictions and the mistakes can be amplified in the subsequent trainings of the model.\n",
        "- co-training\n",
        "  - requires two feature representations associated with the dataset which serve as two different views of the data\n",
        "  - The representations are dissimilar and conditionally independet, but they can provide complementary information about the data. \n",
        "  - We cannot do this for image classification because we have only visual representations of the data.\n",
        "- graph-based models\n",
        "  - labeled and unlabeled samples are represented as different nodes in a graph\n",
        "  - the edges in this graph denote the similarity between nodes.\n",
        "  - The assumption in this approach is that nodes with strong edges are likely to share the same label.\n",
        "  - The algorithm to compute the labels is:\n",
        "    - The unlabeled nodes can be labeled using random-walk over the graph. Based on the strength of the edges.\n",
        "    - The walk ends when a labeled node is reached \n",
        "    - A probability that the random walker started at a particular unlabeled node given that it ended at a specific labeled node is computed. i.e. 2 poitns are similar if they have indistinguishabel starting points.\n",
        "\n",
        "\n",
        "Reference: \n",
        "- https://www.kdnuggets.com/2019/11/tips-class-imbalance-missing-labels.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on labeled data"
      ],
      "metadata": {
        "id": "FB1MI4vtgX2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download model"
      ],
      "metadata": {
        "id": "ROA_n_aAiY5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pytorch MobileNet pretrained model\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
        "# change the Linear output to fit our dataset\n",
        "\n",
        "# the model has initially 1000 outputs\n",
        "# print(model.classifier)\n",
        "# > Sequential(\n",
        "#   (0): Dropout(p=0.2)\n",
        "#   (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
        "# )\n",
        "\n",
        "model.classifier[1] = nn.Linear(1280, 100)\n",
        "print(model.classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOfEof_ggfun",
        "outputId": "ac72ea6a-3aab-4228-ba3f-e30d7d05d736"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.2, inplace=False)\n",
            "  (1): Linear(in_features=1280, out_features=100, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare datasets"
      ],
      "metadata": {
        "id": "PEYc29buibzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_data = 'data/task1/train_data/'\n",
        "# Read the annotations file into a DataFrame\n",
        "df = pd.read_csv(f'{dir_data}annotations.csv')"
      ],
      "metadata": {
        "id": "0EBMTlxkK9vZ"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organize data for pytorch training ( only once )\n",
        "# Define the base directory\n",
        "base_dir = 'data/task1/labeled'\n",
        "\n",
        "# Iterate over the rows in the DataFrame\n",
        "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "    # Extract the path and class from the row\n",
        "    path = row['sample']\n",
        "    label = row['label']\n",
        "    \n",
        "    # Create the directory for the class\n",
        "    class_dir = f'{base_dir}/{label}'\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "    \n",
        "    # Copy the file to the class directory\n",
        "    shutil.copy(f\"data/{path}\", class_dir) \n",
        "\n",
        "#TODO: here I don't want to split the datasets into training and testing\n",
        "# because I want to use all the training and to create a new dataset\n",
        "# which will create labels for the untrained samples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnhwuNg6hnZA",
        "outputId": "28691990-21e0-4541-cb44-154d57f72477"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23555/23555 [00:05<00:00, 4625.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(experiment_info[\"image_processing\"][\"resize\"]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=experiment_info[\"image_processing\"][\"mean\"],\n",
        "                         std=experiment_info[\"image_processing\"][\"std\"]),\n",
        "    ])\n",
        "\n",
        "data_dir = 'data/task1/labeled'\n",
        "image_dataset = datasets.ImageFolder(data_dir, preprocess) \n",
        "dataloader  = torch.utils.data.DataLoader(\n",
        "    image_dataset, \n",
        "    batch_size = experiment_info[\"hyperparameters_data\"][\"batch_size\"],\n",
        "    shuffle = experiment_info[\"hyperparameters_data\"][\"shuffle_dataloader\"], \n",
        "    num_workers = experiment_info[\"hyperparameters_data\"][\"num_workers\"]\n",
        "    )\n",
        "\n",
        "class_names = image_dataset.classes\n",
        "dataset_size = len(image_dataset)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGgy_3qljJsb",
        "outputId": "743c9e5e-30ee-40f0-a339-b5b40760eb43"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start training"
      ],
      "metadata": {
        "id": "Hq_hNMyajIJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, scheduler, optimizer, criterion, dataset_size, dataloader):\n",
        "                     \n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "    \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_loss = running_loss / dataset_size\n",
        "    epoch_acc = running_corrects.double() / dataset_size\n",
        "    return model, epoch_loss, epoch_acc\n",
        "\n",
        "def train_model(model, *args, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "        model, epoch_loss, epoch_acc = train_loop(model, *args)\n",
        "        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # deep copy the model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "D2UyibBtifi1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting hyperparameters\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=experiment_info[\"hyperparameters_training\"][\"learning_rate\"],\n",
        "    )\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(\n",
        "    optimizer, \n",
        "    step_size=experiment_info[\"hyperparameters_training\"][\"scheduler_step_size\"], \n",
        "    gamma=experiment_info[\"hyperparameters_training\"][\"scheduler_gamma\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "Sr6RKnpHig2Z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, \n",
        "                    exp_lr_scheduler, \n",
        "                    optimizer, \n",
        "                    criterion,  \n",
        "                    dataset_size, \n",
        "                    dataloader, \n",
        "                    num_epochs=experiment_info[\"hyperparameters_training\"][\"num_epochs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySuW76bXioXR",
        "outputId": "ecb3d13b-a376-4c96-d047-ca56a96dfa91"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:37<00:00,  7.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.4110 Acc: 0.4470\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:37<00:00,  7.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.1668 Acc: 0.7053\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:38<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.7535 Acc: 0.8063\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:37<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5016 Acc: 0.8720\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:39<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3168 Acc: 0.9249\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:37<00:00,  7.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2043 Acc: 0.9547\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:37<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.1287 Acc: 0.9745\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:39<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0617 Acc: 0.9919\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:37<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0408 Acc: 0.9974\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 737/737 [01:37<00:00,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.0331 Acc: 0.9987\n",
            "\n",
            "Training complete in 16m 18s\n",
            "Best val Acc: 0.998684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), '/gdrive/MyDrive/checkpoints/missing_labels/model_it_1.pt')"
      ],
      "metadata": {
        "id": "gOwyuRb5dgoX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict new set of labels"
      ],
      "metadata": {
        "id": "7LBF-Ncmfwbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the source and destination directories\n",
        "source_dir = 'data/task1/train_data/images/unlabeled'\n",
        "destination_dir = 'data/task1/train_data/images/unlabeled/0'\n",
        "os.makedirs(destination_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "VGAMOM3cqaA4"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over all the files in the source directory\n",
        "for file in tqdm(os.listdir(source_dir)):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
        "        # Construct the source and destination paths\n",
        "        src_path = os.path.join(source_dir, file)\n",
        "        dst_path = os.path.join(destination_dir, file)\n",
        "        # Move the file\n",
        "        shutil.move(src_path, dst_path) "
      ],
      "metadata": {
        "id": "mW1t-HsprUFY",
        "outputId": "f58170bb-82d5-4d72-80ff-c5e53bef26a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26446/26446 [00:00<00:00, 30271.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check to see that all images have been moved to unlabeled/0 dir\n",
        "len(os.listdir(destination_dir)) # 26445"
      ],
      "metadata": {
        "id": "L6lI3CK_spou",
        "outputId": "5fbbb9e3-5fc4-42a3-f360-0312f6c571f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26445"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataloader with unlabeled data.\n",
        "# Dataset folder is a subclass of ImageFolder \n",
        "# Which will allow us to return also the path of the image\n",
        "# because we need it to know which images should be moved \n",
        "\n",
        "from torchvision.datasets import DatasetFolder\n",
        "\n",
        "data_dir = 'data/task1/train_data/images/unlabeled'\n",
        "image_dataset_unlabeled = datasets.ImageFolder(root=data_dir, transform=preprocess)\n",
        "\n",
        "dataloader_unlabeled  = torch.utils.data.DataLoader(\n",
        "    image_dataset_unlabeled, \n",
        "    batch_size = 1, \n",
        "    )\n",
        "\n",
        "dataset_size = len(image_dataset_unlabeled)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fKVLIQKgnHNU"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = {\n",
        "    \"path\":[],\n",
        "    \"confidence\":[],\n",
        "    \"label\":[]\n",
        "}\n",
        "\n",
        "# Each epoch has a training and validation phase \n",
        "model.eval()   # Set model to evaluate mode \n",
        "\n",
        "# Iterate over data.\n",
        "img_path_generator = ((image, path) for (path,_) , (image, _) in zip(image_dataset_unlabeled.samples, dataloader_unlabeled))\n",
        "\n",
        "for inputs, path in tqdm(img_path_generator, total=dataset_size):\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    # forward\n",
        "    with torch.set_grad_enabled(False): # we don't want to train\n",
        "        outputs = model(inputs)\n",
        "        confidence, preds = torch.max(outputs, 1) \n",
        "    predicted_labels[\"path\"].append(path) \n",
        "    predicted_labels[\"confidence\"].append(confidence.item())\n",
        "    predicted_labels[\"label\"].append(preds.item())\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "Qrr3m5F-m6yT",
        "outputId": "16434383-919f-4556-ee26-f7986c7568b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26445/26445 [03:43<00:00, 118.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the predictions"
      ],
      "metadata": {
        "id": "S2EtsR38FTOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a distribution of the convidence scores. To find a threshold\n",
        "counts, bins, patches = plt.hist(predicted_labels[\"confidence\"], bins = 20)\n",
        "\n",
        "# Set x-axis label\n",
        "plt.xlabel('Confidence Score')\n",
        "plt.xticks(bins, bins.astype(int))\n",
        "# Set y-axis label\n",
        "plt.ylabel('Number of Observations')\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Distribution of Confidence Scores')"
      ],
      "metadata": {
        "id": "X-BACmxY85fu",
        "outputId": "1926ebb2-2461-4945-b958-a2653482e299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of Confidence Scores')"
            ]
          },
          "metadata": {},
          "execution_count": 172
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bins)"
      ],
      "metadata": {
        "id": "_MSSEdHR_Mar",
        "outputId": "bda6ecf8-e6ba-4cf0-a3e6-03ab6f90459b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.2711072  -0.63155334  1.00800052  2.64755437  4.28710823  5.92666209\n",
            "  7.56621594  9.2057698  10.84532366 12.48487751 14.12443137 15.76398523\n",
            " 17.40353909 19.04309294 20.6826468  22.32220066 23.96175451 25.60130837\n",
            " 27.24086223 28.88041608 30.51996994]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the top X bins but not more than 10% of the unlabeled dataset\n",
        "# to move into the labeled dataset\n",
        "top10 = experiment_info[\"total_unlabeled\"]*0.1\n",
        "if sum(counts)>top10:\n",
        "    for x in range(20):\n",
        "        top10-=counts[-x-1]\n",
        "        if top10 < 0:\n",
        "            break\n",
        "    n_keep = int(sum(counts[-x:]))\n",
        "else:\n",
        "    n_keep = int(sum(counts))\n",
        "print(n_keep)"
      ],
      "metadata": {
        "id": "osEAvXC9FiNb",
        "outputId": "96825cf6-4517-463e-807a-0c1ebc16f06e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the confidence scores in descending order\n",
        "sorted_confidences = np.sort(predicted_labels[\"confidence\"])[::-1]\n",
        "\n",
        "# Keep the first n_keep scores\n",
        "top_confidences = sorted_confidences[:n_keep]\n",
        "\n",
        "# Find the indices of the top confidences in the original list of confidences\n",
        "top_confidence_indices = [i for i, c in enumerate(predicted_labels[\"confidence\"]) if c in top_confidences]\n",
        "\n",
        "# Use the indices to select the corresponding paths and labels\n",
        "top_confidences = [predicted_labels[\"confidence\"][i] for i in top_confidence_indices]\n",
        "top_paths = [predicted_labels[\"path\"][i] for i in top_confidence_indices]\n",
        "top_labels = [predicted_labels[\"label\"][i] for i in top_confidence_indices]"
      ],
      "metadata": {
        "id": "oNkR_xrpHbCd"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iteration_predictions = {\n",
        "    \"path\":top_paths,\n",
        "    \"confidence\":top_confidences,\n",
        "    \"label\":top_labels\n",
        "}"
      ],
      "metadata": {
        "id": "X3u7tKzgIHaK"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the experiment information from the JSON file\n",
        "num_iteration = 0\n",
        "# Save the experiment information to a JSON file\n",
        "with open(f'iteration_{num_iteration}_images.json', 'w') as f:\n",
        "    json.dump(iteration_predictions, f)"
      ],
      "metadata": {
        "id": "CUV2nr83I8cu"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the experiment information from the JSON file\n",
        "with open(f'iteration_{num_iteration}_images.json', 'r') as f:\n",
        "    iteration_predictions = json.load(f)\n",
        "\n",
        "df_labeled = pd.DataFrame(iteration_predictions)\n"
      ],
      "metadata": {
        "id": "0XWDIovwJPVF"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the images above the trashold in the dataset\n",
        "# Iterate through the selected rows and move the images\n",
        "for index, row in tqdm(df_labeled.iterrows(),total=n_keep):\n",
        "    parts = row['path'].split(\".\")\n",
        "    parts[0]+=f\"_it_{num_iteration}\"\n",
        "    new_name = \".\".join(parts).split('/')[-1]\n",
        "    shutil.copy(row['path'], f\"data/task1/labeled/{row['label']}/{new_name}\")"
      ],
      "metadata": {
        "id": "rZC0SypYKjiO",
        "outputId": "b08ef067-a97b-4f0b-950c-9af84d6de8f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1962/1962 [00:00<00:00, 5296.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Repeat the following iterations of self-training"
      ],
      "metadata": {
        "id": "iPJNQ8vCJbya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "    data_dir = 'data/task1/labeled'\n",
        "    preprocess = transforms.Compose([\n",
        "    transforms.Resize(experiment_info[\"image_processing\"][\"resize\"]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=experiment_info[\"image_processing\"][\"mean\"],\n",
        "                         std=experiment_info[\"image_processing\"][\"std\"]),\n",
        "    ])\n",
        "\n",
        "    image_dataset = datasets.ImageFolder(data_dir, preprocess) \n",
        "    dataloader  = torch.utils.data.DataLoader(\n",
        "        image_dataset, \n",
        "        batch_size = experiment_info[\"hyperparameters_data\"][\"batch_size\"],\n",
        "        shuffle = experiment_info[\"hyperparameters_data\"][\"shuffle_dataloader\"], \n",
        "        num_workers = experiment_info[\"hyperparameters_data\"][\"num_workers\"]\n",
        "        )\n",
        "\n",
        "    class_names = image_dataset.classes\n",
        "    dataset_size = len(image_dataset)\n",
        "    return class_names, dataset_size, dataloader, image_dataset\n",
        "\n",
        "for num_iteration in range(1,10):\n",
        "    class_names, dataset_size, dataloader, image_dataset = create_dataset()\n",
        " \n",
        "    print(num_iteration)"
      ],
      "metadata": {
        "id": "LJ2-pwXZPaXq",
        "outputId": "89e92a0c-224e-42e6-8cc7-376a74851b46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: restart the training on the new dataset\n",
        "# TODO: put all the previous 3 steps in a loop "
      ],
      "metadata": {
        "id": "8Rf6JGxZgOeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW1vKBQjPpcw"
      },
      "outputs": [],
      "source": [
        "# k-fold cross-validation, \n",
        "# ensemble methods, \n",
        "# or importance sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT0e5c1wPpcw"
      },
      "source": [
        "## Test the model on the new dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo7mrv5XgHa6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This will shuffle the images in the dataset \n",
        "# before they are returned to the data loader,\n",
        "# which should help ensure that the validation and training sets\n",
        "# are more balanced.\n",
        "class ShuffledImageFolder(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.indices = torch.randperm(len(dataset))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset[self.indices[index]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "data_dir = 'data/task1/labeled'\n",
        "image_dataset_unshuffled = datasets.ImageFolder(data_dir, preprocess)\n",
        "image_dataset = ShuffledImageFolder(image_dataset_unshuffled)\n",
        "\n",
        "# print(image_datasets)\n",
        "# We don't want to create a single dataset because we want to have a dataset for evaluation also\n",
        "# dataloader  = torch.utils.data.DataLoader(image_dataset, batch_size = 4, shuffle = True, num_workers = 4)\n",
        "\n",
        "# split data into train and val\n",
        "\n",
        "dataset_size = len(image_dataset)\n",
        "print(dataset_size)\n",
        "split = int(dataset_size*0.8)\n",
        "train_size = split\n",
        "print(train_size)\n",
        "val_size = dataset_size - split\n",
        "print(val_size)\n",
        "assert val_size+train_size == dataset_size\n",
        "class_names = image_dataset.dataset.classes\n",
        "\n",
        "# Create a sampler for the training set\n",
        "train_sampler = SubsetRandomSampler(range(split))\n",
        "\n",
        "# Create a sampler for the valuation set\n",
        "val_sampler = SubsetRandomSampler(range(split, dataset_size))\n",
        "\n",
        "# Create DataLoaders for the training and valuation sets\n",
        "train_dataloader = torch.utils.data.DataLoader(image_dataset, batch_size=32, sampler=train_sampler)\n",
        "val_dataloader = torch.utils.data.DataLoader(image_dataset, batch_size=32, sampler=val_sampler, shuffle=False)\n",
        "dataloaders = {\n",
        "    \"train\":train_dataloader,\n",
        "    \"val\":val_dataloader,\n",
        "}\n",
        "dataset_sizes = {\n",
        "    \"train\":train_size,\n",
        "    \"val\":val_size,\n",
        "}\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "diofrUY_jsMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting hyperparameters\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "KoH-8q7gjvjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}